# 智握：语音驱动的视觉抓取智能机械臂

# 一、项目背景与赛题分析

## 1.1 制造业痛点与智能化需求

当前制造业正处于由自动化向智能化转型的关键阶段。传统生产线普遍面临工艺更新周期长、柔性化不足、人机交互智能化水平低等问题，尤其在零件检测与分拣环节中，仍依赖人工识别和操作，效率低且误差率高。
 在此背景下，如何利用人工智能技术实现“感知—决策—执行”一体化，成为智能制造领域的重要方向。通过引入机器视觉、语音交互、大模型算法等多模态智能技术，可以显著提升生产线的自动化与智能协同能力，减少人工干预，改善制造效率和稳定性。

## 1.2 赛题目标与核心技术挑战

本赛题以“智能制造场景零件的智能检测及无序分拣”为主题，旨在推动人工智能技术在实际工业场景中的应用落地。参赛团队需通过多模态大模型与工业设备的结合，完成零件检测、缺陷识别、语音控制分拣等任务，构建一个具备感知、理解与执行能力的智能分拣系统。

该任务的核心技术挑战包括：视觉识别精度与鲁棒性、语音指令的理解与执行、机械臂控制与运动规划、多模态协同融合等等难题。除此之外对项目团队成员的自身技术硬实力与团队合作软实力也是一大挑战。

## 1.3 项目技术切入点与建设目标

本项目“智握：语音驱动的视觉抓取智能机械臂”依托校实验室平台资源开展。实验室长期开展无人机、机器人类项目实践，团队成员电子设计竞赛、智能汽车竞赛与 Robocon 等电子信息类学科竞赛，积累了丰富的机械结构设计、嵌入式控制与计算机视觉经验。看到本赛题后，团队认为该课题不仅具有较高的技术挑战性，更处于人工智能赋能制造业的关键交叉点，兼具产业应用价值与科研创新意义。

项目以企业实际需求为导向，结合实验室已有的硬件条件与算法积累，构建低成本、高扩展性的智能分拣平台。系统以“语音控制+视觉识别+机械臂执行”为核心架构，形成“听、看、动”协同的多模态智能控制体系。

------

## 二、系统总体架构与应用场景设计

### 2.1 系统总体架构与工作原理

![系统框图](C:\Users\曹鑫\OneDrive\Document\3DOF\img\系统框图.png)

### 2.2 模块功能划分与协同机制

系统整体架构遵循“语音理解—任务决策—运动执行”的多层级协同逻辑，主要由三部分组成：语音交互模块（小智AI）、上位机控制模块以及下位机执行模块。三者之间通过标准化通信接口实现数据交互与任务协作，形成稳定高效的多模态控制体系。

#### 语音交互模块
该模块负责语音识别、自然语言解析以及任务意图生成。通过调用本地语音识别引擎 Sense Voice Small，将语音实时转换为文字，并通过 Deepseek 开放平台的 HTTP API 借助大语言模型 Function Calling 机制完成语义理解与指令解析。当识别到有效的操作命令后，模块会将指令封装为结构化任务信息，通过 WebSocket 协议发送至上位机。

#### 上位机控制模块
上位机运行于边缘计算终端，是整个系统的核心调度中心。该模块负责视觉识别、运动学计算、任务调度与状态机管理。上位机接收到小智的指令后，先调用视觉模块进行目标检测与定位，再根据目标位置计算机械臂的运动学逆解，并生成具体的控制参数。随后通过串口通信将执行指令下发至下位机，交由下位机执行。

#### 下位机执行模块
下位机以 ESP32 为核心控制单元，通过串口接收上位机的运动指令并解析执行。其主要任务包括舵机与步进电机的底层控制、姿态调整及夹爪动作执行。通过与基于串口协议闭环 FOC 步进电机控制器配合，实现了机械臂电机控制与抓取动作。下位机实时回传执行状态，上位机根据反馈结果判断任务完成情况，从而形成稳定可靠的通信与控制闭环。

整个系统的通信机制采用分层解耦设计：语音模块与上位机通过 WebSocket 保持低延迟网络连接，实现任务级语义传递；上位机与下位机通过串口通信完成实时控制指令下发与状态反馈，从而实现语音、视觉与控制的多模态融合协同。

### 2.3 工业分拣应用场景与流程描述

在智能制造中，视觉分拣机械臂可实现物料的自动识别与搬运，提升生产线柔性与效率。系统工作流程为：高清摄像头采集工作台图像，小智识别并指令上位机执行抓取任务；上位机进行坐标转换与路径规划后，通过串口下发指令至下位机；下位机控制机械臂和夹爪执行抓取、搬运、投放动作，完成一次分拣循环。整个过程语音可控、视觉自适应，减少人工干预，实现高效、智能的分拣自动化。

------

## 三、机械与电子系统设计

### 3.1 机械结构设计与制造方案

本项目的机械臂采用 RRR 构型三自由度结构，包含旋转、肩、肘三关节，关节轴线位于同一平面，整体呈串联形式。机械部分由团队成员通过 Fusion360 软件自主建模完成，结构件采用 PETG 材料通过 3D 打印制造。

![机械结构](.\img\机械结构.png)

为保证末端执行器的姿态稳定性，机械臂在末端至旋转平台增加了一组平行连杆机构，使末端平台在运动过程中保持水平。关键受力连杆关节处嵌入关节法兰轴承和轴肩螺栓加强固定，并降低关节旋转过程中的阻尼。减速系统采用 1:20 摆线减速器，能在保持速度响应的同时提供足够扭矩并降低回差。

末端执行器采用模块化接口设计，可快速更换为舵机夹爪或吸盘抓具，兼容不同类型的零件抓取任务，并预留安装力或视觉传感器的扩展位置。机械结构在装配完成后进行零位标定和限位校验，以保证运动精度与安全性。

### 3.2 电子系统的设计方案

![母板设计](C:\Users\曹鑫\OneDrive\Document\3DOF\img\母板设计.png)

电子系统由 ESP32 控制核心及其拓展母板和闭环步进电机控制器组成。

主控部分使用自研母板搭载乐鑫科技 ESP32-S3 最小系统开发板，集成电源管理、电机通信接口、CAN 收发器和调试串口。主控负责任务调度、指令解析、通信管理以及下位控制器的协调控制。主控系统使用 3S 锂电池（12V)供电，通过高效降压模块为 ESP32 及外围电路提供 5V/3.3V 稳定电压，并加入过流、欠压保护电路。

电机控制部分采用卡元闭环步进电机控制器，内部以 STM32 为核心，基于磁编码器与 FOC 算法实现电流环、速度环、位置环的全闭环控制，支持位置模式和速度模式两种工作方式。电机控制器与主控板之间通过 CAN 总线通信，实现高实时性和高可靠性的分布式控制结构。

系统整体具备急停、堵转保护、欠压保护与断电复位机制。电路板使用多层 PCB 设计，关键信号线路采用隔离与滤波措施，有效降低电磁干扰。通过模块化连接方式，便于电机、传感器及外围设备的快速接入与维护。

---


## 四、视觉检测与模型训练

### 4.1 任务定义与算法选型依据

### 4.2 模型训练过程与验证结果

### 4.3 视觉检测性能与应用实效

------

## 五、多模态语音交互与智能控制

![小智框架](C:\Users\曹鑫\OneDrive\Document\3DOF\img\小智框架.png)

### 5.1 语音识别与语义理解机制

本系统的语音交互部分完全基于小智 AI 框架实现，形成语音输入、语义理解与动作执行的完整闭环。语音识别模块采用 SenseVoice Small 在本地部署运行，实现实时语音转文本，无需依赖外部网络环境，保证了低延迟与数据安全。识别得到的文字信息由小智框架直接发送至 Deepseek API 进行语义解析与智能应答，从而实现自然语言到任务指令的转换。系统支持多轮对话和上下文记忆，可通过语音完成机械臂启停、模式切换、位置控制、目标抓取等多种操作。

### 5.2 大模型 Function Calling 技术实现

在语义解析阶段，系统采用符合 JSON Schema 2020-12 规范的结构化 JSON 描述方式，结合 Deepseek Function Calling API 实现任务意图识别与指令生成。系统共配置了两个主要功能：
 （1）Robotic-Arm-Control：用于实现基于坐标或关节角度的机械臂精确控制。用户可通过自然语言指令直接指定机械臂的空间位置或关节角度，大模型根据语义内容自动提取参数并生成标准控制指令。
 （2）Robotic-Arm-Catch：用于完成不同目标物体的抓取与分类。系统根据视觉识别结果自动匹配语音中描述的目标类别，实现语音驱动的智能分拣操作。
 通过 Function Calling 技术，大模型在理解语义的同时能够直接调用功能接口，实现自然语言与控制指令的高效映射，显著提升了语音控制的准确性与可扩展性。

### 5.3 语音-视觉-控制一体化执行闭环

语音识别、大模型理解与机械臂执行之间通过 WebSocket 协议实现实时通信。用户的语音指令经解析后，意图识别结果以结构化的 JSON 数据格式发送至机械臂上位机，上位机根据任务类型调用运动学求解与视觉识别模块，生成抓取或移动路径指令，并下发至控制层执行。
在执行过程中，视觉模块实时监测目标位置与夹取状态，若发现偏差，则反馈至上位机进行二次调整，从而形成语音触发、视觉校正、动作反馈的完整控制闭环。该模式实现了语音与视觉的多模态协同，使机械臂能够在复杂环境中完成自主识别、定位与抓取操作。

### 5.4 工业语音交互的创新与实践

本系统在工业语音交互中的创新主要体现在“语音—语义—控制”链路的深度融合。与传统语音指令控制相比，本方案通过大模型的 Function Calling 技术实现了自然语言到结构化控制命令的直接转换，大幅提升了指令表达的灵活性与系统的智能响应能力。
通过本地化语音识别与边缘计算架构，系统在保证数据安全的同时降低了通信延迟，适应工业现场的实时控制需求。语音交互与视觉识别的融合使操作人员无需使用传统控制终端，即可通过口令完成复杂的分拣与检测任务，显著提高了生产线的人机协作效率与智能化水平，为多模态大模型在工业场景中的应用提供了可行的实践路径。

------

## 六、系统集成与实验验证

### 6.1 系统通信架构与状态机逻辑

### 6.2 联动测试方案与稳定性验证

### 6.3 应用场景展示与结果分析

------

## 七、项目成果与创新亮点

### 7.1 技术创新性与应用价值

### 7.2 系统性能指标与测试结论

### 7.3 相对传统方案的优势与改进

------

## 八、问题分析与后续优化方向

### 8.1 当前局限性与技术瓶颈

### 8.2 优化思路与产业化展望

------

## 九、结语

- 项目总结与对未来智能制造的启示